{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cascade cup 2020",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1Jxjht2NGDJ",
        "outputId": "d85283f5-64c7-486e-de42-c14855cf55f0"
      },
      "source": [
        "# installing catboost\n",
        "!pip install catboost"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.24.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzK8e-JI2XJ5",
        "outputId": "955810aa-387f-4883-ce8d-56bbf1ed0870"
      },
      "source": [
        "# Mounting my google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/mydrive; to attempt to forcibly remount, call drive.mount(\"/content/mydrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaWQBz4REkV_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANP_dvZrEzMS"
      },
      "source": [
        "train_data = pd.read_csv(\"mydrive/MyDrive/Cascade Cup 2020/data/train_age_dataset.csv\")\n",
        "test_data = pd.read_csv(\"mydrive/MyDrive/Cascade Cup 2020/data/test_age_dataset.csv\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L46l-wOqHXk7",
        "outputId": "173ca21f-09d9-41e1-9100-068b864836b5"
      },
      "source": [
        "#column_types = np.array([\"r\", \"r\", \"c\", \"c\", \"n\", \"n\", \"n\", \"n\", \"r\", \"r\", \"n\", \"n\", \"n\", \"n\", \"n\", \"r\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"d\"])\n",
        "to_drop=['Unnamed: 0', 'userId']\n",
        "column_types = np.array([\"n\" for i in range(len(train_data.columns))])\n",
        "for i, j in enumerate(train_data.columns):\n",
        "  if j in to_drop:\n",
        "    column_types[i] = 'r' \n",
        "column_types[-1] = \"d\"\n",
        "print(column_types)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['r' 'r' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
            " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'd']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVuMHAGfO3Kh"
      },
      "source": [
        "column_dic = {\"r\": \"redundant\", \n",
        "              \"c\": \"categorical\",\n",
        "              \"n\": \"numeric\",\n",
        "              \"d\": \"dependant\"}"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8QKMIhBQt00",
        "outputId": "7b330c02-5dde-495e-95b7-1a44712ada29"
      },
      "source": [
        "# splitting data into X's and Y's and removing redundant features\n",
        "X = train_data.iloc[:, [x != \"r\" and x != \"d\" for x in column_types]]\n",
        "Y = train_data.iloc[:, [x == \"d\" for x in column_types]]\n",
        "testX = test_data.iloc[:, [x != \"r\" and x != \"d\" for x in column_types[:-1]]]\n",
        "req_cols = column_types[[x != \"r\" and x != \"d\" for x in column_types]]\n",
        "\n",
        "# creating a concatenated dataset for normalizing or standardization\n",
        "concat = pd.concat([X, testX], axis=0)\n",
        "X.shape, Y.shape, testX.shape, concat.shape, req_cols.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((488877, 24), (488877, 1), (54320, 24), (543197, 24), (24,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVSsuHWLSvXJ"
      },
      "source": [
        "# Creating a normalized version of data\n",
        "def normalize(con, train, test):\n",
        "    global req_cols\n",
        "\n",
        "    train_fin = train.copy()\n",
        "    test_fin = test.copy()\n",
        "\n",
        "    max = con.max()\n",
        "    min = con.min()\n",
        "\n",
        "    is_num = (req_cols == \"n\")\n",
        "\n",
        "    train_fin.loc[:, is_num] = (max[is_num] - train_fin.loc[:, is_num]) / (max[is_num] - min[is_num])\n",
        "    test_fin.loc[:, is_num] = (max[is_num] - test_fin.loc[:, is_num]) / (max[is_num] - min[is_num])\n",
        "\n",
        "    return train_fin, test_fin\n",
        "\n",
        "# Creating a standardized version of data\n",
        "def standardize(con, train, test):\n",
        "    global req_cols\n",
        "\n",
        "    train_fin = train.copy()\n",
        "    test_fin = test.copy()\n",
        "\n",
        "    mean = con.mean()\n",
        "    var = con.var(ddof=0)\n",
        "\n",
        "    is_num = (req_cols == \"n\")\n",
        "\n",
        "    train_fin.loc[:, is_num] = (train_fin.loc[:, is_num] - mean[is_num]) / (var[is_num]**0.5)\n",
        "    test_fin.loc[:, is_num] = (test_fin.loc[:, is_num] - mean[is_num]) / (var[is_num]**0.5)\n",
        "\n",
        "    return train_fin, test_fin"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG36E-RBU75E"
      },
      "source": [
        "X_norm, testX_norm = normalize(concat, X, testX)\n",
        "X_stand, testX_stand = standardize(concat, X, testX)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6-SLD1vYMR_"
      },
      "source": [
        "# importing modules from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1KFjGczZ48V",
        "outputId": "acb50e9b-5bca-4bba-85dd-b77fc714d84f"
      },
      "source": [
        "# first splitting into train and valid\n",
        "trainX, validX, trainY, validY = train_test_split(X, Y, test_size=0.1, stratify=Y, random_state=123)\n",
        "trainX.shape, validX.shape, trainY.shape, validY.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((439989, 24), (48888, 24), (439989, 1), (48888, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "elCVIKEeOcKl",
        "outputId": "cb922dff-f2ea-4905-b179-76b2b931bfb8"
      },
      "source": [
        "# here we evaluate CatBoost\n",
        "# model = CatBoostClassifier(task_type=\"GPU\")\n",
        "model = XGBClassifier()\n",
        "model.fit(trainX, np.ravel(trainY))\n",
        "\n",
        "# f1_score for training data\n",
        "trainY_hat = model.predict(trainX)\n",
        "train_f1 = f1_score(trainY, np.ravel(trainY_hat), average=\"weighted\")\n",
        "# f1_score for validation data\n",
        "validY_hat = model.predict(validX)\n",
        "valid_f1 = f1_score(validY, np.ravel(validY_hat), average=\"weighted\")\n",
        "\n",
        "print(train_f1)\n",
        "print(valid_f1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-6facc071f9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model = CatBoostClassifier(task_type=\"GPU\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# f1_score for training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRLc4foPXuc0",
        "outputId": "523629bd-83f7-41d5-a44d-d7113eaeec48"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(trainX, np.ravel(trainY))\n",
        "\n",
        "# f1_score for training data\n",
        "trainY_hat = model.predict(trainX)\n",
        "train_f1 = f1_score(trainY, np.ravel(trainY_hat), average=\"weighted\")\n",
        "# f1_score for validation data\n",
        "validY_hat = model.predict(validX)\n",
        "valid_f1 = f1_score(validY, np.ravel(validY_hat), average=\"weighted\")\n",
        "\n",
        "print(train_f1)\n",
        "print(valid_f1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7334942288214344\n",
            "0.616731659797872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkuUqZmMYrBB",
        "outputId": "3eb328a5-2c58-4991-e0bc-b507aba932b4"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "model = LGBMClassifier()\n",
        "model.fit(trainX, np.ravel(trainY))\n",
        "\n",
        "# f1_score for training data\n",
        "trainY_hat = model.predict(trainX)\n",
        "train_f1 = f1_score(trainY, np.ravel(trainY_hat), average=\"weighted\")\n",
        "# f1_score for validation data\n",
        "validY_hat = model.predict(validX)\n",
        "valid_f1 = f1_score(validY, np.ravel(validY_hat), average=\"weighted\")\n",
        "\n",
        "print(train_f1)\n",
        "print(valid_f1)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7527317431246294\n",
            "0.7434111748375374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_lRFyxivsC_"
      },
      "source": [
        "'''\n",
        "import tensorflow as tf\n",
        "ohe = OneHotEncoder()\n",
        "trainY_ohe = ohe.fit_transform(trainY).toarray()\n",
        "validY_ohe = ohe.fit_transform(validY).toarray()\n",
        "\n",
        "input = tf.keras.Input(shape=(trainX.shape[1],))\n",
        "x = tf.keras.layers.Dense(64, activation=\"relu\")(input)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Dense(4, activation=\"softmax\")(x)\n",
        "model = tf.keras.Model(inputs=input, outputs=x)\n",
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam())\n",
        "model.fit(tf.convert_to_tensor(trainX.values), tf.convert_to_tensor(trainY_ohe), batch_size=64, epochs=10, validation_split=0.1)\n",
        "preds = model.predict(trainX)\n",
        "preds = ohe.inverse_transform(preds)\n",
        "preds\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIrxwRUXbx9O"
      },
      "source": [
        "'''\n",
        "def get_y_hats(models, data):\n",
        "    trainY_hats = []\n",
        "    for model in models:\n",
        "        temp = model.predict(data)\n",
        "        trainY_hats.append(np.ravel(temp))\n",
        "    trainY_hats = np.array(trainY_hats)\n",
        "    return trainY_hats\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69JNUuAwxnQe"
      },
      "source": [
        "'''\n",
        "from collections import Counter\n",
        "def predict_from_multiple(hats): # must be of the shape (num_models, num_samples)\n",
        "    fin = np.zeros(hats.shape[1])\n",
        "    for idx in range(hats.shape[1]):\n",
        "        max_voted = list(dict(Counter(hats[:, idx]).most_common(1)).keys())[0]\n",
        "        fin[idx] = max_voted\n",
        "    return fin\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAAkGxz3dzI2"
      },
      "source": [
        "# now we will generate predictions for test data and export them\n",
        "sample = pd.read_csv(\"mydrive/MyDrive/Cascade Cup 2020/data/sample_submission.csv\")\n",
        "# testY_hats = get_y_hats(models, testX)\n",
        "# testY_hat = predict_from_multiple(testY_hats)\n",
        "testY_hat = model.predict(testX)\n",
        "sample[:] = testY_hat.reshape(-1, 1)\n",
        "sample.to_csv(\"submission_8.csv\", index=False)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYO1dcQkZAeN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}